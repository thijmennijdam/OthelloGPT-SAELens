{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import torch as t\n",
    "import numpy as np\n",
    "\n",
    "from othello_world.mechanistic_interpretability.mech_interp_othello_utils import (\n",
    "    plot_board,\n",
    "    plot_single_board,\n",
    "    plot_board_log_probs,\n",
    "    to_string,\n",
    "    to_int,\n",
    "    int_to_label,\n",
    "    string_to_label,\n",
    "    OthelloBoardState\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 60])\n",
      "torch.Size([1000, 60])\n",
      "torch.Size([100, 60])\n",
      "torch.Size([100, 60])\n",
      "torch.Size([100, 59])\n"
     ]
    }
   ],
   "source": [
    "token_dataset = load_from_disk(\"dummy_othellogpt_dataset\")['tokens'][:1000]\n",
    "token_dataset_string = t.tensor(to_string(token_dataset))\n",
    "\n",
    "print(token_dataset.shape)\n",
    "print(token_dataset.shape)\n",
    "\n",
    "\n",
    "num_games = 100\n",
    "feature = 88\n",
    "\n",
    "focus_games_int = token_dataset[:num_games]\n",
    "focus_games_string = token_dataset_string[:num_games]\n",
    "\n",
    "print(focus_games_int.shape)    \n",
    "print(focus_games_string.shape)\n",
    "\n",
    "activations = t.load(\"saved_feat_acts/all_feat_acts_0-99.pt\")[:num_games, :, feature]\n",
    "print(activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focus states: (100, 60, 8, 8)\n",
      "focus_valid_moves (100, 60, 64)\n"
     ]
    }
   ],
   "source": [
    "def one_hot(list_of_ints, num_classes=64):\n",
    "    out = t.zeros((num_classes,), dtype=t.float32)\n",
    "    out[list_of_ints] = 1.\n",
    "    return out\n",
    "\n",
    "focus_states = np.zeros((num_games, 60, 8, 8), dtype=np.float32)\n",
    "focus_valid_moves = t.zeros((num_games, 60, 64), dtype=t.float32)\n",
    "\n",
    "\n",
    "for i in (range(num_games)):\n",
    "    board = OthelloBoardState()\n",
    "    for j in range(59):\n",
    "        board.umpire(focus_games_string[i, j].item())\n",
    "        focus_states[i, j] = board.state\n",
    "        focus_valid_moves[i, j] = one_hot(board.get_valid_moves())\n",
    "\n",
    "\n",
    "print(\"focus states:\", focus_states.shape)\n",
    "print(\"focus_valid_moves\", tuple(focus_valid_moves.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 60, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "rows = 8\n",
    "cols = 8\n",
    "\n",
    "def state_stack_to_one_hot(state_stack):\n",
    "    '''\n",
    "    Creates a tensor of shape (games, moves, rows=8, cols=8, options=3), where the [g, m, r, c, :]-th entry\n",
    "    is a one-hot encoded vector for the state of game g at move m, at row r and column c. In other words, this\n",
    "    vector equals (1, 0, 0) when the state is empty, (0, 1, 0) when the state is \"their\", and (0, 0, 1) when the\n",
    "    state is \"my\".\n",
    "    '''\n",
    "    one_hot = t.zeros(\n",
    "        state_stack.shape[0], # num games\n",
    "        state_stack.shape[1], # num moves\n",
    "        rows,\n",
    "        cols,\n",
    "        3, # the options: empty, white, or black\n",
    "        device=state_stack.device,\n",
    "        dtype=t.int,\n",
    "    )\n",
    "    one_hot[..., 0] = state_stack == 0 \n",
    "    one_hot[..., 1] = state_stack == -1 \n",
    "    one_hot[..., 2] = state_stack == 1 \n",
    "\n",
    "    return one_hot\n",
    "\n",
    "# We first convert the board states to be in terms of my (+1) and their (-1), rather than black and white\n",
    "alternating = np.array([-1 if i%2 == 0 else 1 for i in range(focus_games_int.shape[1])])\n",
    "flipped_focus_states = focus_states * alternating[None, :, None, None]\n",
    "\n",
    "# We now convert to one-hot encoded vectors\n",
    "focus_states_flipped_one_hot = state_stack_to_one_hot(t.tensor(flipped_focus_states))\n",
    "\n",
    "# Take the argmax (i.e. the index of option empty/their/mine)\n",
    "focus_states_flipped_value = focus_states_flipped_one_hot.argmax(dim=-1)\n",
    "print(focus_states_flipped_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of moves: 31\n",
      "torch.Size([100, 59])\n"
     ]
    }
   ],
   "source": [
    "top_moves = activations > activations.quantile(0.99)\n",
    "n_moves = top_moves.sum().item()\n",
    "print('number of moves:', n_moves)\n",
    "print(top_moves.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly_utils import imshow\n",
    "alpha = \"ABCDEFGH\"\n",
    "\n",
    "def plot_square_as_board(state, filename, diverging_scale=True, **kwargs):\n",
    "    '''Takes a square input (8 by 8) and plot it as a board. Can do a stack of boards via facet_col=0'''\n",
    "    kwargs = {\n",
    "        \"y\": [i for i in alpha],\n",
    "        \"x\": [str(i) for i in range(8)],\n",
    "        \"color_continuous_scale\": \"RdBu\" if diverging_scale else \"Blues\",\n",
    "        \"color_continuous_midpoint\": 0. if diverging_scale else None,\n",
    "        \"aspect\": \"equal\",\n",
    "        **kwargs\n",
    "    }\n",
    "    imshow(state, filename=filename, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "layer = 5\n",
    "\n",
    "focus_states_flipped_value = focus_states_flipped_value.to(device)\n",
    "board_state_at_top_moves = t.stack([\n",
    "    (focus_states_flipped_value == 2)[:, :-1][top_moves].float().mean(0),\n",
    "    (focus_states_flipped_value == 1)[:, :-1][top_moves].float().mean(0),\n",
    "    (focus_states_flipped_value == 0)[:, :-1][top_moves].float().mean(0)\n",
    "])\n",
    "\n",
    "print(board_state_at_top_moves.shape)\n",
    "\n",
    "# plot_square_as_board(\n",
    "#     board_state_at_top_moves,\n",
    "#     filename=f\"top_{n_moves}_moves_layer{layer}_feature{feature}\", \n",
    "#     facet_col=0,\n",
    "#     facet_labels=[\"Mine\", \"Theirs\", \"Blank\"],\n",
    "#     title=f\"Aggregated top {n_moves} moves for neuron L{layer}F{feature}\", \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# print how many are above 0.99\n",
    "is_board_state_feature = board_state_at_top_moves > 0.75\n",
    "print(is_board_state_feature.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_square_as_board(\n",
    "#     is_board_state_feature,\n",
    "#     filename=f\"top_{n_moves}_moves_layer{layer}_feature{feature}\", \n",
    "#     facet_col=0,\n",
    "#     facet_labels=[\"Mine\", \"Theirs\", \"Blank\"],\n",
    "#     title=f\"Aggregated top {n_moves} moves for neuron L{layer}F{feature}\", \n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
